{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "number_anchor = 9\n",
    "anchor_ratios = [(1,1), (1,2), (2,1), (2,2), (2,4), (4,2), (4,4), (4,8), (8,4)]\n",
    "anchor_default_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets_path = 'train2014/'\n",
    "annotations_path = 'annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_json_path = annotations_path + 'instances_train2014.json'\n",
    "annotations_json = json.load(open(annotations_json_path,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_dict ={annotations_json['categories'][i]['id']:i for i in range(len(annotations_json['categories']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_name(category_id):\n",
    "    return annotations_json['categories'][label_id_dict[annotation['category_id']]]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "def load_images(size):\n",
    "    global datasets\n",
    "    datasets = {}\n",
    "    for i, image_info in enumerate(annotations_json['images'][:size]):\n",
    "        img_name = train_datasets_path + image_info['file_name']\n",
    "        print('{} % ,loading {}'.format((i+1)*100//size,img_name))\n",
    "        \n",
    "        img = cv2.imread(img_name)\n",
    "        img, resize_ratio = resize_by_padding(img,input_shape[1],input_shape[0])\n",
    "        \n",
    "        data = {'img':img,\n",
    "                'resize_ratio':resize_ratio,\n",
    "                'index':i,\n",
    "                'original_resolution':(image_info['height'], image_info['width'])\n",
    "               }\n",
    "        datasets[image_info['id']] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_by_padding(img,net_width,net_height):\n",
    "    img_h,img_w = img.shape[:2]\n",
    "\n",
    "    if img_h > img_w:\n",
    "        new_h = int(net_height)\n",
    "        new_w = int(img_w * net_height / img_h)\n",
    "    else:\n",
    "        new_w = int(net_width)\n",
    "        new_h = int(img_h * net_width / img_w)\n",
    "\n",
    "#     bbox[0] *= new_w / img_w\n",
    "#     bbox[1] *= new_h / img_h\n",
    "#     bbox[2] *= new_w / img_w\n",
    "#     bbox[3] *= new_h / img_h\n",
    "    resize_ratio = (new_w / img_w, new_h / img_h)\n",
    "    \n",
    "    img = img[:,:,::-1]\n",
    "    img = img/255.\n",
    "    resized = cv2.resize(img,(new_w,new_h))\n",
    "    base_img = np.ones((net_height,net_width,3)) * 0.5\n",
    "    base_img[(net_height-new_h)//2 : (net_height+new_h)//2,(net_width-new_w)//2 : (net_width+new_w)//2,:] = resized\n",
    "    \n",
    "#     bbox[0] += (net_width - new_w)//2\n",
    "#     bbox[1] += (net_height - new_h)//2\n",
    "    \n",
    "    resize_offset = ((net_width - new_w)//2, (net_height - new_h)//2)\n",
    "    return base_img, (resize_ratio, resize_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_resized_bbox(bbox,resize_ratio):\n",
    "    ratio, offset = resize_ratio\n",
    "    return [bbox[0]*ratio[0]+offset[0], bbox[1]*ratio[1]+offset[1], bbox[2]*ratio[0], bbox[3]*ratio[1]]\n",
    "def convert_bbox_to_ratio(bbox,img_shape):\n",
    "    return [bbox[0]/img_shape[1], bbox[1]/img_shape[0], bbox[2]/img_shape[1], bbox[3]/img_shape[0]]\n",
    "def convert_cocobbox_to_anchorbbox(bbox):\n",
    "    return [bbox[0]+(bbox[2]//2), bbox[1]+(bbox[3]//2), bbox[2], bbox[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(img,bbox_ratio,color):\n",
    "    print(bbox_ratio)\n",
    "    bbox = \n",
    "#     return cv2.rectangle(img,(x1,y1),(x2,y2),color,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 14., 28., 28.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.copy(base_anchor)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:2] += 5*stride_size,10*stride_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([array([54., 94.]), 5], dtype=object), 5, 4], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([x[:2],5,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_anchor = np.array([\n",
    "    anchor_default_size/2, anchor_default_size/2, \n",
    "    anchor_default_size, anchor_default_size\n",
    "])\n",
    "\n",
    "def generate_anchor_bbox():\n",
    "    anchors = []\n",
    "    for y_box in range(net_height):\n",
    "        for x_box in range(net_width):\n",
    "            tmp_anchor = np.copy(base_anchor)\n",
    "            tmp_anchor[:2] += x_box*stride_size, y_box*stride_size\n",
    "            tmp_anchors = []\n",
    "            for ratio in anchor_ratios:\n",
    "                tmp = np.copy(tmp_anchor)\n",
    "                tmp[2:] *= ratio\n",
    "                tmp = convert_bbox_to_ratio(tmp, input_shape[:2])\n",
    "                tmp_anchors.append(tmp)\n",
    "            tmp_anchors = np.array(tmp_anchors)\n",
    "            anchors.append(tmp_anchors)\n",
    "    anchors = np.array(anchors)\n",
    "            \n",
    "#             x1, y1 = x_box*stride_size, y_box*stride_size\n",
    "#             x2, y2 = x1 + stride_size, y1 + stride_size\n",
    "#             centroid_x = x1 + stride_size//2\n",
    "#             centroid_y = y1 + stride_size//2\n",
    "            \n",
    "#             anchors_bbox = [[centroid_x ,\\\n",
    "#                              centroid_y ,\\\n",
    "#                              anchor_default_size*anchor_ratio[1], \\\n",
    "#                              anchor_default_size*anchor_ratio[0], \\\n",
    "#                             ] for anchor_ratio in anchor_ratios]\n",
    "#             anchors_bbox = [convert_bbox_to_ratio(anchor_bbox, input_shape[:2])\n",
    "#                             for anchor_bbox in anchors_bbox]\n",
    "#             anchors.append(anchors_bbox)\n",
    "    return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_height, net_width = 28, 28\n",
    "stride_size = input_shape[0] // net_height\n",
    "cls = np.empty((len(datasets), net_height, net_width, number_anchor*2))\n",
    "rgs = np.empty((len(datasets), net_height, net_width, number_anchor*4))\n",
    "def initilize_output():\n",
    "    global datasets\n",
    "    for i, annotation in enumerate(annotations_json['annotations']):\n",
    "        try:\n",
    "            datasets[annotation['image_id']]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        class_id = annotation['category_id']\n",
    "        truth_bbox = annotation['bbox']\n",
    "        truth_bbox = convert_cocobbox_to_anchorbbox(truth_bbox)\n",
    "\n",
    "        datasets[annotation['image_id']]['anchors'] = generate_anchor_bbox()\n",
    "\n",
    "        truth_bbox = convert_resized_bbox(truth_bbox, datasets[annotation['image_id']]['resize_ratio']) \n",
    "        truth_bbox = convert_bbox_to_ratio(truth_bbox, input_shape[:2])\n",
    "        datasets[annotation['image_id']]['truth_bbox'] = truth_bbox\n",
    "#     img = images[images_dict[annotation['image_id']]]\n",
    "#     img = draw_box(img,truth_bbox,(0,255,0))\n",
    "#     images[images_dict[annotation['image_id']]] = img\n",
    "#     plt.imshow(img)\n",
    "#     label_id, label_name = annotation['category_id'], get_label_name(annotation['category_id'])\n",
    "#     print(label_id, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 % ,loading train2014/COCO_train2014_000000057870.jpg\n",
      "20 % ,loading train2014/COCO_train2014_000000384029.jpg\n",
      "30 % ,loading train2014/COCO_train2014_000000222016.jpg\n",
      "40 % ,loading train2014/COCO_train2014_000000520950.jpg\n",
      "50 % ,loading train2014/COCO_train2014_000000069675.jpg\n",
      "60 % ,loading train2014/COCO_train2014_000000547471.jpg\n",
      "70 % ,loading train2014/COCO_train2014_000000122688.jpg\n",
      "80 % ,loading train2014/COCO_train2014_000000392136.jpg\n",
      "90 % ,loading train2014/COCO_train2014_000000398494.jpg\n",
      "100 % ,loading train2014/COCO_train2014_000000090570.jpg\n"
     ]
    }
   ],
   "source": [
    "load_images(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initilize_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['truth_bbox', 'anchors', 'original_resolution', 'index', 'resize_ratio', 'img'])\n",
      "[0.0625 0.0625 0.125  0.125 ]\n",
      "[0.0625 0.0625 0.125  0.25  ]\n",
      "[0.0625 0.0625 0.25   0.125 ]\n",
      "[0.0625 0.0625 0.25   0.25  ]\n",
      "[0.0625 0.0625 0.25   0.5   ]\n",
      "[0.0625 0.0625 0.5    0.25  ]\n",
      "[0.0625 0.0625 0.5    0.5   ]\n",
      "[0.0625 0.0625 0.5    1.    ]\n",
      "[0.0625 0.0625 1.     0.5   ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-e8a25fa59eef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anchors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3205\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    647\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    648\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 649\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets[57870]\n",
    "print(data.keys())\n",
    "img = np.copy(data['img'])\n",
    "for bbox in data['anchors'][0][:]:\n",
    "    img = draw_box(img,bbox,(0,255,0))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_id', 'id', 'iscrowd', 'category_id', 'area', 'bbox', 'segmentation'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['category_id', 'id', 'iscrowd', 'segmentation', 'area', 'bbox', 'image_id'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_json['annotations'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'coco_url': 'http://images.cocodataset.org/train2014/COCO_train2014_000000057870.jpg',\n",
       "  'date_captured': '2013-11-14 16:28:13',\n",
       "  'file_name': 'COCO_train2014_000000057870.jpg',\n",
       "  'flickr_url': 'http://farm4.staticflickr.com/3153/2970773875_164f0c0b83_z.jpg',\n",
       "  'height': 480,\n",
       "  'id': 57870,\n",
       "  'license': 5,\n",
       "  'width': 640},\n",
       " {'area': 421.47274999999996,\n",
       "  'bbox': [85.939, 100.8595, 14.049, 6.6850000000000005],\n",
       "  'category_id': 58,\n",
       "  'id': 89,\n",
       "  'image_id': 50518,\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': [[252.46,\n",
       "    208.17,\n",
       "    267.96,\n",
       "    210.11,\n",
       "    280.14,\n",
       "    213.98,\n",
       "    285.68,\n",
       "    221.45,\n",
       "    279.59,\n",
       "    227.27,\n",
       "    270.73,\n",
       "    223.12,\n",
       "    256.61,\n",
       "    218.69,\n",
       "    253.02,\n",
       "    217.3,\n",
       "    248.03,\n",
       "    220.07,\n",
       "    245.54,\n",
       "    215.92,\n",
       "    245.82,\n",
       "    209.55,\n",
       "    249.69,\n",
       "    208.45]]})"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_json['images'][0], annotations_json['annotations'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': array([12])} [12]\n",
      "{'1': array([12])} 15\n"
     ]
    }
   ],
   "source": [
    "x = {'1':np.array([12])}\n",
    "y = x['1']\n",
    "print(x,y)\n",
    "y = 15 \n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'width': 640, 'coco_url': 'http://images.cocodataset.org/train2014/COCO_train2014_000000057870.jpg', 'flickr_url': 'http://farm4.staticflickr.com/3153/2970773875_164f0c0b83_z.jpg', 'height': 480, 'file_name': 'COCO_train2014_000000057870.jpg', 'id': 57870, 'date_captured': '2013-11-14 16:28:13', 'license': 5}\n",
      "1 {'width': 640, 'coco_url': 'http://images.cocodataset.org/train2014/COCO_train2014_000000384029.jpg', 'flickr_url': 'http://farm3.staticflickr.com/2422/3577229611_3a3235458a_z.jpg', 'height': 429, 'file_name': 'COCO_train2014_000000384029.jpg', 'id': 384029, 'date_captured': '2013-11-14 16:29:45', 'license': 5}\n",
      "2 {'width': 480, 'coco_url': 'http://images.cocodataset.org/train2014/COCO_train2014_000000222016.jpg', 'flickr_url': 'http://farm2.staticflickr.com/1431/1118526611_09172475e5_z.jpg', 'height': 640, 'file_name': 'COCO_train2014_000000222016.jpg', 'id': 222016, 'date_captured': '2013-11-14 16:37:59', 'license': 1}\n"
     ]
    }
   ],
   "source": [
    "for k,v in enumerate(annotations_json['images'][:3]):\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "480023",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-a0289e90e81e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mannotations_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mannotations_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 480023"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 0\n",
      "end 0\n",
      "start 1\n",
      "end 1\n",
      "start 2\n",
      "end 2\n",
      "start 3\n",
      "ERRROR!!!!!!!!!\n",
      "start 4\n",
      "end 4\n",
      "start 5\n",
      "end 5\n",
      "start 6\n",
      "end 6\n",
      "start 7\n",
      "end 7\n",
      "start 8\n",
      "end 8\n",
      "start 9\n",
      "end 9\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
