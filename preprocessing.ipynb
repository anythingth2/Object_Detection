{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "number_anchor = 9\n",
    "anchor_ratios = [(1,1), (1,2), (2,1), (2,2), (2,4), (4,2), (4,4), (4,8), (8,4)]\n",
    "anchor_default_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets_path = 'train2014/'\n",
    "annotations_path = 'annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_json_path = annotations_path + 'instances_train2014.json'\n",
    "annotations_json = json.load(open(annotations_json_path,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_dict ={annotations_json['categories'][i]['id']:i for i in range(len(annotations_json['categories']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_name(category_id):\n",
    "    return annotations_json['categories'][label_id_dict[annotation['category_id']]]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "def load_images(size):\n",
    "    global datasets\n",
    "    datasets = {}\n",
    "    for i, image_info in enumerate(annotations_json['images'][:size]):\n",
    "        img_name = train_datasets_path + image_info['file_name']\n",
    "        print('{} % ,loading {}'.format((i+1)*100//size,img_name))\n",
    "        \n",
    "        img = cv2.imread(img_name)\n",
    "        img, resize_ratio = resize_by_padding(img,input_shape[1],input_shape[0])\n",
    "        \n",
    "        data = {'img':img,\n",
    "                'resize_ratio':resize_ratio,\n",
    "                'index':i,\n",
    "                'original_resolution':(image_info['height'], image_info['width'])\n",
    "               }\n",
    "        datasets[image_info['id']] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_by_padding(img,net_width,net_height):\n",
    "    img_h,img_w = img.shape[:2]\n",
    "\n",
    "    if img_h > img_w:\n",
    "        new_h = int(net_height)\n",
    "        new_w = int(img_w * net_height / img_h)\n",
    "    else:\n",
    "        new_w = int(net_width)\n",
    "        new_h = int(img_h * net_width / img_w)\n",
    "\n",
    "    resize_ratio = (new_w / img_w, new_h / img_h)\n",
    "    \n",
    "    img = img[:,:,::-1]\n",
    "    img = img/255.\n",
    "    resized = cv2.resize(img,(new_w,new_h))\n",
    "    base_img = np.ones((net_height,net_width,3)) * 0.5\n",
    "    base_img[(net_height-new_h)//2 : (net_height+new_h)//2,(net_width-new_w)//2 : (net_width+new_w)//2,:] = resized\n",
    "    \n",
    "    resize_offset = ((net_width - new_w)//2, (net_height - new_h)//2)\n",
    "    return base_img, (resize_ratio, resize_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(img,bbox_ratio,color,grid=False,centroid=False,debug=False):\n",
    "    bbox = np.copy(bbox_ratio)\n",
    "    bbox[[0,2]] *= input_shape[1]\n",
    "    bbox[[1,3]] *= input_shape[0]\n",
    "    \n",
    "    if grid:\n",
    "        y_grid = np.arange(input_shape[0]//net_height,input_shape[0],input_shape[0]//net_height)\n",
    "        x_grid = np.arange(input_shape[1]//net_width,input_shape[1],input_shape[1]//net_width)\n",
    "        img[y_grid] = (0,0,0)\n",
    "        img[ : , x_grid] = (0,0,0)\n",
    "        \n",
    "    if centroid:\n",
    "        img = cv2.circle(img,(int(bbox[0]),int(bbox[1])),1,color,thickness=1)\n",
    "    \n",
    "    coor = [bbox[0] - bbox[2]/2, bbox[1] - bbox[3] / 2, bbox[0] + bbox[2]/2, bbox[1] + bbox[3] / 2]\n",
    "    coor = [int(x) for x in coor]\n",
    "    coor = tuple(coor)\n",
    "    if debug:\n",
    "        print(coor)\n",
    "    img = cv2.rectangle(img,coor[:2],coor[2:],color,1)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_resized_bbox(bbox,resize_ratio):\n",
    "    ratio, offset = resize_ratio\n",
    "    return [bbox[0]*ratio[0]+offset[0], bbox[1]*ratio[1]+offset[1], bbox[2]*ratio[0], bbox[3]*ratio[1]]\n",
    "def convert_bbox_to_ratio(bbox,img_shape):\n",
    "    return [bbox[0]/img_shape[1], bbox[1]/img_shape[0], bbox[2]/img_shape[1], bbox[3]/img_shape[0]]\n",
    "def convert_cocobbox_to_anchorbbox(bbox):\n",
    "    return [bbox[0]+(bbox[2]//2), bbox[1]+(bbox[3]//2), bbox[2], bbox[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchor_bbox(stride_size):\n",
    "    base_anchor = np.array([\n",
    "            stride_size/2, stride_size/2, \n",
    "            anchor_default_size, anchor_default_size\n",
    "            ])\n",
    "#     anchors = []\n",
    "#     for y_box in range(net_height):\n",
    "#         for x_box in range(net_width):\n",
    "            \n",
    "#             anchors.append(tmp_anchors)\n",
    "#     anchors = np.array(anchors)\n",
    "#     return anchors\n",
    "    tmp_anchor = np.copy(base_anchor)\n",
    "#     tmp_anchor[:2] += x_box*stride_size, y_box*stride_size\n",
    "    tmp_anchors = []\n",
    "    for ratio in anchor_ratios:\n",
    "        tmp = np.copy(tmp_anchor)\n",
    "        tmp[2:] *= ratio\n",
    "        tmp = convert_bbox_to_ratio(tmp, input_shape[:2])\n",
    "        tmp_anchors.append(tmp)\n",
    "    tmp_anchors = np.array(tmp_anchors)\n",
    "    return tmp_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox1,bbox2):\n",
    "    box_coor1 = [bbox1[0] - bbox1[2] / 2,\n",
    "                 bbox1[1] - bbox1[3] / 2,\n",
    "                 bbox1[0] + bbox1[2] / 2,\n",
    "                 bbox1[1] + bbox1[3] / 2\n",
    "                ]\n",
    "    box_coor2 = [bbox2[0] - bbox2[2] / 2,\n",
    "                 bbox2[1] - bbox2[3] / 2,\n",
    "                 bbox2[0] + bbox2[2] / 2,\n",
    "                 bbox2[1] + bbox2[3] / 2\n",
    "                ]\n",
    "    \n",
    "    x_start_right = max(box_coor1[0], box_coor2[0])\n",
    "    x_end_left = min(box_coor1[2],box_coor2[2])\n",
    "    y_start_bottom = max(box_coor1[1],box_coor2[1])\n",
    "    y_end_top = min(box_coor1[3],box_coor2[3])\n",
    "    \n",
    "    #check overlap\n",
    "    if not((x_start_right < x_end_left) and (y_start_bottom < y_end_top)):\n",
    "        return 0.0\n",
    "    intersection = abs((x_start_right - x_end_left) * (y_start_bottom - y_end_top))\n",
    "    union = bbox1[2]*bbox1[3] + bbox2[2]*bbox2[3] - intersection\n",
    "    return intersection / union\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_height, net_width = 28, 28\n",
    "\n",
    "def map_gtbox():\n",
    "    global datasets\n",
    "    for i, annotation in enumerate(annotations_json['annotations']):\n",
    "        try:\n",
    "            datasets[annotation['image_id']]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        class_id = annotation['category_id']\n",
    "        truth_bbox = annotation['bbox']\n",
    "        truth_bbox = convert_cocobbox_to_anchorbbox(truth_bbox)\n",
    "\n",
    "        truth_bbox = convert_resized_bbox(truth_bbox, datasets[annotation['image_id']]['resize_ratio']) \n",
    "        truth_bbox = convert_bbox_to_ratio(truth_bbox, input_shape[:2])\n",
    "        if 'truth_bbox' in datasets[annotation['image_id']]:\n",
    "            datasets[annotation['image_id']]['truth_bbox'].append(truth_bbox)\n",
    "        else:\n",
    "            datasets[annotation['image_id']]['truth_bbox'] = [truth_bbox]\n",
    "def compute_class_score_and_rgs(iou_thresold,debug=False):\n",
    "    global datasets\n",
    "    \n",
    "    stride_size = input_shape[0] // net_height\n",
    "    base_anchors = generate_anchor_bbox(stride_size)\n",
    "    \n",
    "    cls = np.zeros((len(datasets), net_height, net_width, number_anchor*2))\n",
    "    cls[:,:,:] = np.array([0,1]*number_anchor)\n",
    "    rgs = np.empty((len(datasets), net_height, net_width, number_anchor*4))\n",
    "    rgs[:,:,:] = base_anchors.reshape((36,))\n",
    "    \n",
    "    if debug:\n",
    "        fig = plt.figure(figsize=(224,224))\n",
    "        \n",
    "    for i, key in enumerate(datasets):\n",
    "        data = datasets[key]\n",
    "        truth_bboxes = data['truth_bbox']\n",
    "\n",
    "            \n",
    "        for gt_bbox in truth_bboxes:\n",
    "            n_column = int(gt_bbox[0]*input_shape[0] // stride_size)\n",
    "            n_row = int(gt_bbox[1]*input_shape[1]  // stride_size)\n",
    "            anchors = np.copy(base_anchors)\n",
    "            anchors[:,0] += n_column*stride_size/input_shape[0]\n",
    "            anchors[:,1] += n_row*stride_size/input_shape[1]\n",
    "            \n",
    "            if debug:\n",
    "                img = np.copy(data['img'])\n",
    "                img = draw_box(img,gt_bbox,(0,255,0),centroid=True)\n",
    "            \n",
    "            for j, anchor in enumerate(anchors):\n",
    "                iou_score = iou(gt_bbox,anchor)\n",
    "                if iou_score > iou_thresold :\n",
    "                    cls[:, n_row, n_column, j*2:j*2+2] = [1,0]\n",
    "                    if debug:\n",
    "                        fig.add_subplot(5,4,j+1)                        \n",
    "                        plt.imshow(draw_box(img, anchor, (255,0,0),centroid=True))\n",
    "    return cls,rgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "100 % ,loading train2014/COCO_train2014_000000057870.jpg\n"
     ]
    }
   ],
   "source": [
    "load_images(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_gtbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls,rgs = compute_class_score_and_rgs(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = np.zeros((len(datasets), net_height, net_width, number_anchor*2))\n",
    "cls.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
